{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb18d846",
   "metadata": {},
   "source": [
    "# Combining the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e4240",
   "metadata": {},
   "source": [
    "### Importing librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd96b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import string\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import statistics\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f428a63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the stopwords corpus if needed\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a486c181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httplib2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from httplib2) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install httplib2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0975cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: uritemplate in c:\\users\\msi\\anaconda3\\lib\\site-packages (4.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\msi\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install uritemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271ad48",
   "metadata": {},
   "source": [
    "### Load the trained models from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6556395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:07:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "phishing_model = joblib.load('phishing_model.joblib')\n",
    "fake_news_model = joblib.load('fake_news_model.joblib')\n",
    "spam_model_xgb = joblib.load('spam_model_xgb.joblib')\n",
    "sentiment_analysis_model = joblib.load('sentiment_analysis_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9bdb09",
   "metadata": {},
   "source": [
    "### Enter the testing email body here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0291be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is urgent! Someone has tried to access to your account. Please follow the link below to enter your credentials and reset your password\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186408d",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc496ca",
   "metadata": {},
   "source": [
    "To prepare the test text for the models, we implemented preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d20e787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define a function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML and nbsp encoding\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Remove numbers not attached to any other word\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "\n",
    "    # Normalize unicode characters\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words and punctuation\n",
    "    stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Return list of tokens\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5083fa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['urgent', 'someone', 'tried', 'access', 'account', 'please', 'follow', 'link', 'enter', 'credentials', 'reset', 'password']\n"
     ]
    }
   ],
   "source": [
    "preprocessed_text = preprocess_text(text)\n",
    "print(preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "990a20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_phishing_model_vocab(preprocessed_text):\n",
    "    # Create a CountVectorizer object\n",
    "    vectorizer = CountVectorizer(vocabulary=phishing_model.get_booster().feature_names)\n",
    "    \n",
    "    # Apply BoW to the preprocessed text\n",
    "    bow_matrix = vectorizer.fit_transform([preprocessed_text])\n",
    "\n",
    "    # create a DataFrame from the bag of words matrix\n",
    "    bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "    return bow_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "22583008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000000</th>\n",
       "      <th>000008</th>\n",
       "      <th>00000e2511c8</th>\n",
       "      <th>00000eur</th>\n",
       "      <th>000066</th>\n",
       "      <th>00084740000484800938</th>\n",
       "      <th>000999</th>\n",
       "      <th>000m</th>\n",
       "      <th>...</th>\n",
       "      <th>â_x0080__x0094_30</th>\n",
       "      <th>â_x0080__x0094_and</th>\n",
       "      <th>â_x0080__x0094_but</th>\n",
       "      <th>â_x0080__x0094_no</th>\n",
       "      <th>â_x0080__x0094_that</th>\n",
       "      <th>â_x0080__x0094_the</th>\n",
       "      <th>â_x0082_</th>\n",
       "      <th>â_x0096_</th>\n",
       "      <th>ï2007</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000000  000008  00000e2511c8  00000eur  000066  \\\n",
       "0   0    0       0       0             0         0       0   \n",
       "\n",
       "   00084740000484800938  000999  000m  ...  â_x0080__x0094_30  \\\n",
       "0                     0       0     0  ...                  0   \n",
       "\n",
       "   â_x0080__x0094_and  â_x0080__x0094_but  â_x0080__x0094_no  \\\n",
       "0                   0                   0                  0   \n",
       "\n",
       "   â_x0080__x0094_that  â_x0080__x0094_the  â_x0082_  â_x0096_  ï2007  Topic  \n",
       "0                    0                   0         0         0      0      0  \n",
       "\n",
       "[1 rows x 32182 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df_phish = bag_of_words_phishing_model_vocab(' '.join(preprocessed_text))\n",
    "bow_df_phish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "42caede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_fake_news_model_vocab(preprocessed_text):\n",
    "    # Create a CountVectorizer object\n",
    "    vectorizer = CountVectorizer(vocabulary=fake_news_model.get_booster().feature_names)\n",
    "    \n",
    "    # Apply BoW to the preprocessed text\n",
    "    bow_matrix = vectorizer.fit_transform([preprocessed_text])\n",
    "\n",
    "    # create a DataFrame from the bag of words matrix\n",
    "    bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "    return bow_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e02bfa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>003</th>\n",
       "      <th>0040</th>\n",
       "      <th>005380ks</th>\n",
       "      <th>01</th>\n",
       "      <th>0100</th>\n",
       "      <th>02</th>\n",
       "      <th>025</th>\n",
       "      <th>029</th>\n",
       "      <th>03</th>\n",
       "      <th>033</th>\n",
       "      <th>...</th>\n",
       "      <th>zitser</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zona</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoomph</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuker</th>\n",
       "      <th>zzzzaaaacccchhh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   003  0040  005380ks  01  0100  02  025  029  03  033  ...  zitser  zoe  \\\n",
       "0    0     0         0   0     0   0    0    0   0    0  ...       0    0   \n",
       "\n",
       "   zona  zone  zoo  zoomph  zucker  zuckerberg  zuker  zzzzaaaacccchhh  \n",
       "0     0     0    0       0       0           0      0                0  \n",
       "\n",
       "[1 rows x 32296 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df_fake_news = bag_of_words_fake_news_model_vocab(' '.join(preprocessed_text))\n",
    "bow_df_fake_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "20604a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_spam_model_xgb_vocab(preprocessed_text):\n",
    "    # Create a CountVectorizer object\n",
    "    vectorizer = CountVectorizer(vocabulary=spam_model_xgb.get_booster().feature_names)\n",
    "    \n",
    "    # Apply BoW to the preprocessed text\n",
    "    bow_matrix = vectorizer.fit_transform([preprocessed_text])\n",
    "\n",
    "    # create a DataFrame from the bag of words matrix\n",
    "    bow_df_spam = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "    return bow_df_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d6074841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>003</th>\n",
       "      <th>0040</th>\n",
       "      <th>005380ks</th>\n",
       "      <th>01</th>\n",
       "      <th>0100</th>\n",
       "      <th>02</th>\n",
       "      <th>025</th>\n",
       "      <th>029</th>\n",
       "      <th>03</th>\n",
       "      <th>033</th>\n",
       "      <th>...</th>\n",
       "      <th>zitser</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zona</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoomph</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuker</th>\n",
       "      <th>zzzzaaaacccchhh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   003  0040  005380ks  01  0100  02  025  029  03  033  ...  zitser  zoe  \\\n",
       "0    0     0         0   0     0   0    0    0   0    0  ...       0    0   \n",
       "\n",
       "   zona  zone  zoo  zoomph  zucker  zuckerberg  zuker  zzzzaaaacccchhh  \n",
       "0     0     0    0       0       0           0      0                0  \n",
       "\n",
       "[1 rows x 32296 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df_spam = bag_of_words_fake_news_model_vocab(' '.join(preprocessed_text))\n",
    "bow_df_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d85290cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>07xxxxxxxxx</th>\n",
       "      <th>08700621170150p</th>\n",
       "      <th>08702840625comuk</th>\n",
       "      <th>08718726270150gbpmtmsg18</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>10am7pm</th>\n",
       "      <th>10k</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yun</th>\n",
       "      <th>yunny</th>\n",
       "      <th>yup</th>\n",
       "      <th>zed</th>\n",
       "      <th>zoe</th>\n",
       "      <th>üll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 3105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   07xxxxxxxxx  08700621170150p  08702840625comuk  08718726270150gbpmtmsg18  \\\n",
       "0            0                0                 0                         0   \n",
       "\n",
       "   10  100  1000  10000  10am7pm  10k  ...  youre  youve  yr  yummy  yun  \\\n",
       "0   0    0     0      0        0    0  ...      0      0   0      0    0   \n",
       "\n",
       "   yunny  yup  zed  zoe  üll  \n",
       "0      0    0    0    0    0  \n",
       "\n",
       "[1 rows x 3105 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have preprocessed_text and trained_logistic_model defined\n",
    "bow_df_spam = bag_of_words_spam_model_xgb_vocab(' '.join(preprocessed_text))\n",
    "\n",
    "bow_df_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db43f5f",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b84b8",
   "metadata": {},
   "source": [
    "## Phishing classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b376d4",
   "metadata": {},
   "source": [
    "Predicting the likelihood of the test email being a phishing email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7bbb06c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of this email being a phishing one is : 0.8338311\n"
     ]
    }
   ],
   "source": [
    "# Use the phishing detection loaded model to make predictions on the test text\n",
    "phishing_scores = phishing_model.predict_proba(bow_df_phish)[:, 1]\n",
    "phishing_score = phishing_scores[0]\n",
    "print('The probability of this email being a phishing one is :',phishing_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a9d5c1",
   "metadata": {},
   "source": [
    "## Malicious URL detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2600f70",
   "metadata": {},
   "source": [
    "Estimating the probability that the test email is a phishing email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "224c7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The URL is a phishing site with a 0.97 probability.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# replace YOUR_API_KEY with your actual VirusTotal API key\n",
    "url = 'https://www.virustotal.com/vtapi/v2/url/report'\n",
    "params = {'apikey': '0b7998a0f881d9dcf72c78041fa0cc2ca11433bd5343f33845e535b2453785f4', 'resource': 'http://appleid.apple.com-app.es/'}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    if result['response_code'] == 1:\n",
    "        if result['positives'] > 0:\n",
    "            # calculate the probability of how likely the URL is a phishing site\n",
    "            url_score = 1 - (result['positives'] / result['total'])\n",
    "            print('The URL is a phishing site with a {:.2f} probability.'.format(url_score))\n",
    "        else:\n",
    "            print('The URL is safe.')\n",
    "    else:\n",
    "        print('The URL is not in the VirusTotal database.')\n",
    "else:\n",
    "    print('Error:', response.status_code, response.reason)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62fe754",
   "metadata": {},
   "source": [
    "## Spam classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912aa6b6",
   "metadata": {},
   "source": [
    "Predicting the likelihood of the test email being a spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b7c58bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of this email being a spam : 0.80242026\n"
     ]
    }
   ],
   "source": [
    "# Use the phishing detection loaded model to make predictions on the test text\n",
    "spam_scores = spam_model_xgb.predict_proba(bow_df_spam)[:, 1]\n",
    "spam_score = spam_scores[0]\n",
    "print('The probability of this email being a spam :',spam_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c6147",
   "metadata": {},
   "source": [
    "## Fake news detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b1a186",
   "metadata": {},
   "source": [
    "Anticipating the probability that an email includes misinformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2f133abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of this email containing fake news is : 0.9966377\n"
     ]
    }
   ],
   "source": [
    "# Use the fake news loaded model to make predictions on the test text\n",
    "fake_news_scores = fake_news_model.predict_proba(bow_df_fake_news)[:, 1]\n",
    "fake_news_score = fake_news_scores[0]\n",
    "\n",
    "print('The probability of this email containing fake news is :',fake_news_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb64ec5",
   "metadata": {},
   "source": [
    "## Cyberbullying detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb6a35",
   "metadata": {},
   "source": [
    "Predicting the likelihood of an email containing cyberbullying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "65dc42b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The toxicity score of this email is : 0.025203144\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "API_KEY = 'AIzaSyD4otRh6Suo--QAuHQqPgpU1wj3wRaThAs'\n",
    "\n",
    "def get_toxicity_score(text):\n",
    "    client = discovery.build(\n",
    "      \"commentanalyzer\",\n",
    "      \"v1alpha1\",\n",
    "      developerKey=API_KEY,\n",
    "      discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "      static_discovery=False,\n",
    "    )\n",
    "\n",
    "    analyze_request = {\n",
    "      'comment': { 'text': text },\n",
    "      'requestedAttributes': {'TOXICITY': {}}\n",
    "    }\n",
    "\n",
    "\n",
    "    response = client.comments().analyze(body=analyze_request).execute()\n",
    "    toxicity_score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "    return toxicity_score\n",
    "\n",
    "toxicity_score=get_toxicity_score(text)\n",
    "print('The toxicity score of this email is :', toxicity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d791d",
   "metadata": {},
   "source": [
    "## Sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc61435",
   "metadata": {},
   "source": [
    "Estimating the likelihood that the test email is a phishing attempt by analyzing only the emotions conveyed in the message through natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "799d8401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is urgent! Someone has tried to access to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  fear  anger  \\\n",
       "0  This is urgent! Someone has tried to access to...     1      0   \n",
       "\n",
       "   anticipation  trust  surprise  positive  negative  sadness  disgust  joy  \n",
       "0             1      1         1         0         1        0        0    0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nrclex import NRCLex\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_emotions(text):\n",
    "    sentiment = NRCLex(text) \n",
    "    mapping = {'anticip': 'anticipation'}\n",
    "    emotions = {mapping.get(k, k): v for k, v in sentiment.affect_frequencies.items()}\n",
    "    return emotions\n",
    "\n",
    "# Extract emotions from the text\n",
    "emotions = extract_emotions(text)\n",
    "# Create a DataFrame from the emotions dictionary\n",
    "df_emotions = pd.DataFrame([emotions])\n",
    "\n",
    "# Convert counts to binary values\n",
    "df_emotions = df_emotions.applymap(lambda x: int(x > 0))\n",
    "\n",
    "# Create a DataFrame with the text column\n",
    "df_text = pd.DataFrame({\"Text\": [text]})\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df = pd.concat([df_text, df_emotions], axis=1)\n",
    "#df = df.drop(columns=['anticip'])\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4a5f9ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is urgent! Someone has tried to access to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  fear  anger  \\\n",
       "0  This is urgent! Someone has tried to access to...     1      0   \n",
       "\n",
       "   anticipation  trust  surprise  positive  negative  sadness  disgust  joy  \\\n",
       "0             1      1         1         0         1        0        0    0   \n",
       "\n",
       "   Sentiment  \n",
       "0        0.0  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Define a function to get sentiment polarity of each text\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# Apply the function to each text in the 'text' column of the dataframe\n",
    "df['Sentiment'] = df['Text'].apply(get_sentiment)\n",
    "\n",
    "# Print the updated dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8a1d1366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fear  anger  anticipation  trust  surprise  positive  negative  sadness  \\\n",
       "0     1      0             1      1         1         0         1        0   \n",
       "\n",
       "   disgust  joy  Sentiment  \n",
       "0        0    0        0.0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ad20d",
   "metadata": {},
   "source": [
    "## Calculating the technical score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "173de0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The technical score is : 0.7249517686061117\n"
     ]
    }
   ],
   "source": [
    "technical_scores_list=[phishing_score, fake_news_score, toxicity_score,url_score,spam_score]\n",
    "technical_score = sum(technical_scores_list)/len(technical_scores_list)\n",
    "print('The technical score is :',technical_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef8a6f7",
   "metadata": {},
   "source": [
    "## Calculating the emotional score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "41b8e13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of this email being a phishing one based on sentiment analysis is : 0.512806892904256\n"
     ]
    }
   ],
   "source": [
    "# Use the fake news loaded model to make predictions on the test text\n",
    "emotional_scores = sentiment_analysis_model.predict_proba(df)[:, 1]\n",
    "emotional_score = emotional_scores[0]\n",
    "print('The probability of this email being a phishing one based on sentiment analysis is :',emotional_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8fc91",
   "metadata": {},
   "source": [
    "## Final Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c59a6c",
   "metadata": {},
   "source": [
    "We combined both the technical and the emotional scores by calculating their mean function. If the final calculated score is higher than 0.5, then it's a phishing email. Otherwise, it's legit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b01cfdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Final score is : 0.6188793307551839\n"
     ]
    }
   ],
   "source": [
    "final_scores_list=[technical_score, emotional_score]\n",
    "final_score = sum(final_scores_list)/len(final_scores_list)\n",
    "print('The Final score is :',final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "11908033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test text is a phishing email !\n"
     ]
    }
   ],
   "source": [
    "if (final_score>= 0.5):\n",
    "    Class=1\n",
    "    print(\"The test text is a phishing email !\");\n",
    "else:\n",
    "    Class=0\n",
    "    print(\"The test text is a legitimate email !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7dafa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
